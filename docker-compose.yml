services:
  # Note: llama.cpp servers run natively on macOS for Metal acceleration
  # Use scripts/start-llama-servers.sh to start them
  # Docker services below are for MCP, Redis, and Orchestrator only

  # MCP Server (Codebase + Tools)
  mcp-server:
    build:
      context: .
      dockerfile: Dockerfile.mcp
    container_name: mcp-server
    ports:
      - "9001:8000"
    volumes:
      - .:/codebase  # Mount your actual codebase
    environment:
      - CODEBASE_ROOT=/codebase
      - MCP_PORT=8000
    restart: unless-stopped


  # Redis (Agent State + Memory)
  redis:
    image: redis:7-alpine
    container_name: redis-agent-memory
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 3

  # Qdrant (Vector Database for RAG)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant-vector-db
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC
    volumes:
      - qdrant_data:/qdrant/storage
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Orchestrator - High Mode (all 6 models, Reviewer validation)
  orchestrator-high:
    build:
      context: .
      dockerfile: Dockerfile.orchestrator
    container_name: orchestrator-high
    ports:
      - "8080:8080"
    depends_on:
      mcp-server:
        condition: service_started
      redis:
        condition: service_healthy
    volumes:
      - .:/app
      - ./agents:/app/agents
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - CODEBASE_ROOT=/app
      - PROMPTS_DIR=/app/agents
      - PREPROCESSOR_URL=http://host.docker.internal:8000/v1/chat/completions
      - PLANNER_URL=http://host.docker.internal:8001/v1/chat/completions
      - CODER_URL=http://host.docker.internal:8002/v1/chat/completions
      - REVIEWER_URL=http://host.docker.internal:8003/v1/chat/completions
      - VOTER_URL=http://host.docker.internal:8004/v1/chat/completions
      - MAKER_NUM_CANDIDATES=5
      - MAKER_VOTE_K=3
      - MAKER_MODE=high
      - MCP_CODEBASE_URL=http://mcp-server:8000
      - QDRANT_URL=http://qdrant:6333
      - EMBEDDING_MODEL=nomic-embed-text-v1.5
      - RAG_COLLECTION_NAME=codebase_docs
      - RAG_INDEX_PATH=/app/data/rag_indexes/codebase.index
      - MAX_CONTEXT_TOKENS=32000
      - RECENT_WINDOW_TOKENS=8000
      - SUMMARY_CHUNK_SIZE=4000
      - AGENT_TIMEOUT_MS=300000
      - MCP_TIMEOUT_MS=30000
      - PHOENIX_ENDPOINT=http://phoenix:6006/v1/traces
      - ENABLE_LONG_RUNNING=true
      - TRIGGER_ENABLED=false
      - EE_MODE=true
    restart: unless-stopped
    command: python -m orchestrator.api_server

  # Orchestrator - Low Mode (5 models, Planner reflection validation)
  orchestrator-low:
    build:
      context: .
      dockerfile: Dockerfile.orchestrator
    container_name: orchestrator-low
    ports:
      - "8081:8080"
    depends_on:
      mcp-server:
        condition: service_started
      redis:
        condition: service_healthy
    volumes:
      - .:/app
      - ./agents:/app/agents
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - CODEBASE_ROOT=/app
      - PROMPTS_DIR=/app/agents
      - PREPROCESSOR_URL=http://host.docker.internal:8000/v1/chat/completions
      - PLANNER_URL=http://host.docker.internal:8001/v1/chat/completions
      - CODER_URL=http://host.docker.internal:8002/v1/chat/completions
      - REVIEWER_URL=http://host.docker.internal:8003/v1/chat/completions
      - VOTER_URL=http://host.docker.internal:8004/v1/chat/completions
      - MAKER_NUM_CANDIDATES=5
      - MAKER_VOTE_K=3
      - MAKER_MODE=low
      - MCP_CODEBASE_URL=http://mcp-server:8000
      - QDRANT_URL=http://qdrant:6333
      - EMBEDDING_MODEL=nomic-embed-text-v1.5
      - RAG_COLLECTION_NAME=codebase_docs
      - RAG_INDEX_PATH=/app/data/rag_indexes/codebase.index
      - MAX_CONTEXT_TOKENS=32000
      - RECENT_WINDOW_TOKENS=8000
      - SUMMARY_CHUNK_SIZE=4000
      - AGENT_TIMEOUT_MS=300000
      - MCP_TIMEOUT_MS=30000
      - PHOENIX_ENDPOINT=http://phoenix:6006/v1/traces
      - ENABLE_LONG_RUNNING=true
      - TRIGGER_ENABLED=false
      - EE_MODE=true
    restart: unless-stopped
    command: python -m orchestrator.api_server

  # Phoenix (Observability & Evaluation)
  phoenix:
    image: arizephoenix/phoenix:latest
    container_name: phoenix-observability
    ports:
      - "6006:6006"  # UI
      - "4317:4317"  # OTLP gRPC
      - "4318:4318"  # OTLP HTTP
    environment:
      - PHOENIX_WORKING_DIR=/data
    volumes:
      - phoenix_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6006/health"]
      interval: 10s
      timeout: 5s
      retries: 3

volumes:
  redis_data:
  qdrant_data:
  phoenix_data:

networks:
  default:
    name: local-agents

